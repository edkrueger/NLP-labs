{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "    \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some light EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "df = pd.read_csv('yelp_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Crust is not good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0  positive                           Wow... Loved this place.\n",
       "1  negative                                 Crust is not good.\n",
       "2  negative          Not tasty and the texture was just nasty.\n",
       "3  positive  Stopped by during the late May bank holiday of...\n",
       "4  positive  The selection on the menu was great and so wer..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the first 5 observations from the data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the unique classes\n",
    "\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    500\n",
       "positive    500\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the class balance\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].values\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.69      0.74       134\n",
      "    positive       0.69      0.82      0.75       116\n",
      "\n",
      "    accuracy                           0.75       250\n",
      "   macro avg       0.75      0.75      0.75       250\n",
      "weighted avg       0.76      0.75      0.75       250\n",
      "\n",
      "CPU times: user 25.5 ms, sys: 1.82 ms, total: 27.4 ms\n",
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "naive_bayes = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', binary=True),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gausian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.61      0.69       134\n",
      "    positive       0.64      0.80      0.71       116\n",
      "\n",
      "    accuracy                           0.70       250\n",
      "   macro avg       0.71      0.71      0.70       250\n",
      "weighted avg       0.72      0.70      0.70       250\n",
      "\n",
      "CPU times: user 202 ms, sys: 20.5 ms, total: 223 ms\n",
      "Wall time: 98.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gaussian_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),    \n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "gaussian_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {gaussian_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, gaussian_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Bigram Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75       134\n",
      "    positive       0.70      0.84      0.76       116\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.77      0.76      0.76       250\n",
      "\n",
      "CPU times: user 145 ms, sys: 4.99 ms, total: 150 ms\n",
      "Wall time: 56.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        binary=True,\n",
    "        ngram_range=(1, 2)\n",
    "    ),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "bigram_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, bigram_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.764 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.79      0.78       134\n",
      "    positive       0.75      0.73      0.74       116\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 83.2 ms, sys: 2.12 ms, total: 85.3 ms\n",
      "Wall time: 62.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logistic_regression = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.80      0.79       134\n",
      "    positive       0.76      0.74      0.75       116\n",
      "\n",
      "    accuracy                           0.77       250\n",
      "   macro avg       0.77      0.77      0.77       250\n",
      "weighted avg       0.77      0.77      0.77       250\n",
      "\n",
      "CPU times: user 29.7 ms, sys: 1.93 ms, total: 31.6 ms\n",
      "Wall time: 32.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.78       134\n",
      "    positive       0.76      0.70      0.73       116\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.76      0.75      0.75       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 28 ms, sys: 1.83 ms, total: 29.9 ms\n",
      "Wall time: 75.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "normalized_lr = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    Normalizer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "normalized_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {normalized_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, normalized_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78       134\n",
      "    positive       0.74      0.74      0.74       116\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 171 ms, sys: 2.7 ms, total: 173 ms\n",
      "Wall time: 98.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1,2)\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "bigram_tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, bigram_tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression with Automatic Corpus Specific Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.80      0.78       134\n",
      "    positive       0.75      0.71      0.73       116\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.76      0.75      0.75       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 69.2 ms, sys: 1.35 ms, total: 70.5 ms\n",
      "Wall time: 26.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mindf_max_tfidf_lr = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        min_df=2,\n",
    "        max_df=.9\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "mindf_max_tfidf_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {mindf_max_tfidf_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, mindf_max_tfidf_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Linear Seperation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.71      0.72       134\n",
      "    positive       0.67      0.69      0.68       116\n",
      "\n",
      "    accuracy                           0.70       250\n",
      "   macro avg       0.70      0.70      0.70       250\n",
      "weighted avg       0.70      0.70      0.70       250\n",
      "\n",
      "CPU times: user 1.13 s, sys: 58.3 ms, total: 1.19 s\n",
      "Wall time: 396 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_lda = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),\n",
    "    LinearDiscriminantAnalysis()\n",
    ")\n",
    "\n",
    "tfidf_lda.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_lda.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_lda.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.768 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.77      0.78       134\n",
      "    positive       0.74      0.77      0.75       116\n",
      "\n",
      "    accuracy                           0.77       250\n",
      "   macro avg       0.77      0.77      0.77       250\n",
      "weighted avg       0.77      0.77      0.77       250\n",
      "\n",
      "CPU times: user 105 ms, sys: 1.95 ms, total: 107 ms\n",
      "Wall time: 29.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_svc = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),\n",
    "    LinearSVC()\n",
    ")\n",
    "\n",
    "tfidf_svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_svc.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Lasso, Ridge and ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.764 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78       134\n",
      "    positive       0.74      0.75      0.75       116\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 4.7 s, sys: 6.56 ms, total: 4.7 s\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression_lasso = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegressionCV(\n",
    "        penalty='l1',\n",
    "        solver='saga' \n",
    "    )\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression_lasso.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression_lasso.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression_lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.79      0.79       134\n",
      "    positive       0.76      0.77      0.76       116\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.78      0.78      0.78       250\n",
      "weighted avg       0.78      0.78      0.78       250\n",
      "\n",
      "CPU times: user 212 ms, sys: 2.14 ms, total: 214 ms\n",
      "Wall time: 213 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression_ridge = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegressionCV(\n",
    "        penalty='l2',\n",
    "        solver='saga' \n",
    "    )\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression_ridge.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression_ridge.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression_ridge.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.79      0.79       134\n",
      "    positive       0.76      0.77      0.76       116\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.78      0.78      0.78       250\n",
      "weighted avg       0.78      0.78      0.78       250\n",
      "\n",
      "CPU times: user 43.3 s, sys: 34 ms, total: 43.3 s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression_elasticnet = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegressionCV(\n",
    "        penalty='elasticnet',\n",
    "        l1_ratios=[0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "        solver='saga' \n",
    "    )\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression_elasticnet.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression_elasticnet.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression_elasticnet.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
