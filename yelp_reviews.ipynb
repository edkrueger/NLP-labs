{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "    \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some light EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "df = pd.read_csv('yelp_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Crust is not good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0  positive                           Wow... Loved this place.\n",
       "1  negative                                 Crust is not good.\n",
       "2  negative          Not tasty and the texture was just nasty.\n",
       "3  positive  Stopped by during the late May bank holiday of...\n",
       "4  positive  The selection on the menu was great and so wer..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the first 5 observations from the data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the unique classes\n",
    "\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    500\n",
       "negative    500\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the class balance\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].values\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.69      0.74       134\n",
      "    positive       0.69      0.82      0.75       116\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       250\n",
      "   macro avg       0.75      0.75      0.75       250\n",
      "weighted avg       0.76      0.75      0.75       250\n",
      "\n",
      "CPU times: user 25.1 ms, sys: 3.55 ms, total: 28.7 ms\n",
      "Wall time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "naive_bayes = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', binary=True),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gausian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy: 0.7 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.61      0.69       134\n",
      "    positive       0.64      0.80      0.71       116\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       250\n",
      "   macro avg       0.71      0.71      0.70       250\n",
      "weighted avg       0.72      0.70      0.70       250\n",
      "\n",
      "CPU times: user 248 ms, sys: 16 ms, total: 264 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gaussian_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),    \n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "gaussian_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {gaussian_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, gaussian_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Bigram Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75       134\n",
      "    positive       0.70      0.84      0.76       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.77      0.76      0.76       250\n",
      "\n",
      "CPU times: user 67 ms, sys: 27.8 ms, total: 94.8 ms\n",
      "Wall time: 94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        binary=True,\n",
    "        ngram_range=(1, 2)\n",
    "    ),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, bigram_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.764 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.79      0.78       134\n",
      "    positive       0.75      0.73      0.74       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 25.8 ms, sys: 1.94 ms, total: 27.7 ms\n",
      "Wall time: 26.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logistic_regression = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.80      0.79       134\n",
      "    positive       0.76      0.74      0.75       116\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       250\n",
      "   macro avg       0.77      0.77      0.77       250\n",
      "weighted avg       0.77      0.77      0.77       250\n",
      "\n",
      "CPU times: user 22.9 ms, sys: 1.24 ms, total: 24.1 ms\n",
      "Wall time: 23.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.78       134\n",
      "    positive       0.76      0.70      0.73       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.75      0.75       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 26.1 ms, sys: 1.77 ms, total: 27.9 ms\n",
      "Wall time: 26.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "normalized_lr = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    Normalizer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "normalized_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {normalized_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, normalized_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78       134\n",
      "    positive       0.74      0.74      0.74       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 56.6 ms, sys: 1.88 ms, total: 58.5 ms\n",
      "Wall time: 35.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1,2)\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "bigram_tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, bigram_tfidf_logistic_regression.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
