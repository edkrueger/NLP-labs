{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "    \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some light EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "df = pd.read_csv('yelp_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Crust is not good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0  positive                           Wow... Loved this place.\n",
       "1  negative                                 Crust is not good.\n",
       "2  negative          Not tasty and the texture was just nasty.\n",
       "3  positive  Stopped by during the late May bank holiday of...\n",
       "4  positive  The selection on the menu was great and so wer..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the first 5 observations from the data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the unique classes\n",
    "\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    500\n",
       "negative    500\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the class balance\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].values\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.69      0.74       134\n",
      "    positive       0.69      0.82      0.75       116\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       250\n",
      "   macro avg       0.75      0.75      0.75       250\n",
      "weighted avg       0.76      0.75      0.75       250\n",
      "\n",
      "CPU times: user 24.3 ms, sys: 1.85 ms, total: 26.2 ms\n",
      "Wall time: 24.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "naive_bayes = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', binary=True),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gausian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.61      0.69       134\n",
      "    positive       0.64      0.80      0.71       116\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       250\n",
      "   macro avg       0.71      0.71      0.70       250\n",
      "weighted avg       0.72      0.70      0.70       250\n",
      "\n",
      "CPU times: user 174 ms, sys: 18.6 ms, total: 193 ms\n",
      "Wall time: 96.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gaussian_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),    \n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "gaussian_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {gaussian_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, gaussian_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Bigram Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75       134\n",
      "    positive       0.70      0.84      0.76       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.77      0.76      0.76       250\n",
      "\n",
      "CPU times: user 143 ms, sys: 4.37 ms, total: 147 ms\n",
      "Wall time: 63.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        binary=True,\n",
    "        ngram_range=(1, 2)\n",
    "    ),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "bigram_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, bigram_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.764 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.79      0.78       134\n",
      "    positive       0.75      0.73      0.74       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 117 ms, sys: 2.61 ms, total: 120 ms\n",
      "Wall time: 90.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logistic_regression = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.80      0.79       134\n",
      "    positive       0.76      0.74      0.75       116\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       250\n",
      "   macro avg       0.77      0.77      0.77       250\n",
      "weighted avg       0.77      0.77      0.77       250\n",
      "\n",
      "CPU times: user 25.6 ms, sys: 1.95 ms, total: 27.5 ms\n",
      "Wall time: 27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.78       134\n",
      "    positive       0.76      0.70      0.73       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.75      0.75       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 25.7 ms, sys: 1.69 ms, total: 27.4 ms\n",
      "Wall time: 49.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "normalized_lr = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    Normalizer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "normalized_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {normalized_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, normalized_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78       134\n",
      "    positive       0.74      0.74      0.74       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 95.3 ms, sys: 5.36 ms, total: 101 ms\n",
      "Wall time: 73.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1,2)\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "bigram_tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, bigram_tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression with Automatic Corpus Specific Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.80      0.78       134\n",
      "    positive       0.75      0.71      0.73       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       250\n",
      "   macro avg       0.76      0.75      0.75       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "CPU times: user 75 ms, sys: 1.24 ms, total: 76.2 ms\n",
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mindf_max_tfidf_lr = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        min_df=2,\n",
    "        max_df=.9\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "mindf_max_tfidf_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {mindf_max_tfidf_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, mindf_max_tfidf_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Linear Seperation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.71      0.72       134\n",
      "    positive       0.67      0.69      0.68       116\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       250\n",
      "   macro avg       0.70      0.70      0.70       250\n",
      "weighted avg       0.70      0.70      0.70       250\n",
      "\n",
      "CPU times: user 1.71 s, sys: 73 ms, total: 1.78 s\n",
      "Wall time: 793 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_lda = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),\n",
    "    LinearDiscriminantAnalysis()\n",
    ")\n",
    "\n",
    "tfidf_lda.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_lda.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_lda.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.71      0.72       134\n",
      "    positive       0.67      0.69      0.68       116\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       250\n",
      "   macro avg       0.70      0.70      0.70       250\n",
      "weighted avg       0.70      0.70      0.70       250\n",
      "\n",
      "CPU times: user 799 ms, sys: 21.7 ms, total: 821 ms\n",
      "Wall time: 293 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkrueger/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_svc = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),\n",
    "    LinearSVC()\n",
    ")\n",
    "\n",
    "tfidf_lda.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_lda.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_lda.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
